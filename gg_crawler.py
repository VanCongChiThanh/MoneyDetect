from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import requests
import os
import time
from PIL import Image
import io

currencies = {
    "vnd_1000": "tá» 1000 Ä‘á»“ng",
}

base_dir = "vnd_currency"
os.makedirs(base_dir, exist_ok=True)

target_images = 20
min_width = 180
min_height = 180

# Thiáº¿t láº­p Selenium
options = webdriver.ChromeOptions()
options.add_argument("--disable-gpu")
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

def check_image_size(image_data):
    try:
        with Image.open(io.BytesIO(image_data)) as img:
            width, height = img.size
            return width >= min_width and height >= min_height
    except Exception as e:
        print(f"Lá»—i khi kiá»ƒm tra kÃ­ch thÆ°á»›c: {e}")
        return False

try:
    for folder_name, keyword in currencies.items():
        save_dir = os.path.join(base_dir, folder_name)
        os.makedirs(save_dir, exist_ok=True)

        downloaded_images = 0
        print(f"\nğŸ” Báº¯t Ä‘áº§u crawl hÃ¬nh áº£nh cho: {keyword}")
        url = f"https://www.google.com/search?tbm=isch&q={keyword.replace(' ', '+')}"
        driver.get(url)

        # Cuá»™n Ä‘á»ƒ load thÃªm áº£nh
        for _ in range(25):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        img_tags = soup.find_all("img")
        print(f"ğŸ“¸ TÃ¬m tháº¥y {len(img_tags)} áº£nh trÃªn trang")

        for i, img in enumerate(img_tags):
            if downloaded_images >= target_images:
                break

            img_url = img.get("src") or img.get("data-src")
            if img_url and img_url.startswith("http"):
                try:
                    headers = {"User-Agent": "Mozilla/5.0"}
                    response = requests.get(img_url, headers=headers, timeout=10)
                    response.raise_for_status()
                    img_data = response.content

                    if check_image_size(img_data):
                        img_name = f"{folder_name}_{downloaded_images}.jpg"
                        img_path = os.path.join(save_dir, img_name)
                        with open(img_path, "wb") as f:
                            f.write(img_data)
                        print(f"âœ… ÄÃ£ lÆ°u: {img_name}")
                        downloaded_images += 1
                    else:
                        print(f"âš ï¸ Bá» qua áº£nh vÃ¬ kÃ­ch thÆ°á»›c nhá»: {img_url}")

                except Exception as e:
                    print(f"âŒ Lá»—i táº£i áº£nh {img_url}: {e}")
                    continue

        print(f"ğŸ¯ ÄÃ£ táº£i {downloaded_images} áº£nh cho {keyword}")

finally:
    driver.quit()

print("\nâœ… HoÃ n táº¥t crawl toÃ n bá»™!")